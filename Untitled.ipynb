{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47546f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing BraTS23 dataset from: /raid/compass/mobarak/datasets/brats2023/valid/official_valid\n",
      "Preparing time: 69.11\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "from subprocess import call\n",
    "import time\n",
    "\n",
    "import nibabel\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "def load_nifty(directory, example_id, suffix):\n",
    "    return nibabel.load(os.path.join(directory, example_id + \"-\" + suffix + \".nii.gz\"))\n",
    "\n",
    "\n",
    "def load_channels(d, example_id):\n",
    "    return [load_nifty(d, example_id, suffix) for suffix in [\"t2f\", \"t1n\", \"t1c\", \"t2w\"]]\n",
    "\n",
    "\n",
    "def get_data(nifty, dtype=\"int16\"):\n",
    "    if dtype == \"int16\":\n",
    "        data = np.abs(nifty.get_fdata().astype(np.int16))\n",
    "        data[data == -32768] = 0\n",
    "        return data\n",
    "    return nifty.get_fdata().astype(np.uint8)\n",
    "\n",
    "\n",
    "def prepare_nifty(d):\n",
    "    example_id = d.split(\"/\")[-1]\n",
    "    flair, t1, t1ce, t2 = load_channels(d, example_id)\n",
    "    affine, header = flair.affine, flair.header\n",
    "    vol = np.stack([get_data(flair), get_data(t1), get_data(t1ce), get_data(t2)], axis=-1)\n",
    "    vol = nibabel.nifti1.Nifti1Image(vol, affine, header=header)\n",
    "    nibabel.save(vol, os.path.join(d, example_id + \".nii.gz\"))\n",
    "\n",
    "    if os.path.exists(os.path.join(d, example_id + \"-seg.nii.gz\")):\n",
    "        seg = load_nifty(d, example_id, \"seg\")\n",
    "        affine, header = seg.affine, seg.header\n",
    "        vol = get_data(seg, \"unit8\")\n",
    "        vol[vol == 4] = 3\n",
    "        seg = nibabel.nifti1.Nifti1Image(vol, affine, header=header)\n",
    "        nibabel.save(seg, os.path.join(d, example_id + \"-seg.nii.gz\"))\n",
    "\n",
    "\n",
    "def prepare_dirs(data, train):\n",
    "    img_path, lbl_path = os.path.join(data, \"images\"), os.path.join(data, \"labels\")\n",
    "    call(f\"mkdir {img_path}\", shell=True)\n",
    "    if train:\n",
    "        call(f\"mkdir {lbl_path}\", shell=True)\n",
    "    dirs = glob(os.path.join(data, \"BraTS*\"))\n",
    "    for d in dirs:\n",
    "        if \"-\" in d.split(\"/\")[-1]:\n",
    "            files = glob(os.path.join(d, \"*.nii.gz\"))\n",
    "            for f in files:\n",
    "                if \"t2f\" in f or \"t1n\" in f or \"t1c\" in f or \"t2w\" in f:\n",
    "                    continue\n",
    "                if \"-seg\" in f:\n",
    "                    call(f\"mv {f} {lbl_path}\", shell=True)\n",
    "                else:\n",
    "                    call(f\"mv {f} {img_path}\", shell=True)\n",
    "        call(f\"rm -rf {d}\", shell=True)\n",
    "\n",
    "\n",
    "def prepare_dataset_json(data, train=True):\n",
    "    images, labels = glob(os.path.join(data, \"images\", \"*\")), glob(os.path.join(data, \"labels\", \"*\"))\n",
    "    images = sorted([img.replace(data + \"/\", \"\") for img in images])\n",
    "    labels = sorted([lbl.replace(data + \"/\", \"\") for lbl in labels])\n",
    "\n",
    "    modality = {\"0\": \"t2f\", \"1\": \"t1n\", \"2\": \"t1c\", \"3\": \"t2w\"}\n",
    "    labels_dict = {\"0\": \"background\", \"1\": \"edema\", \"2\": \"non-enhancing tumor\", \"3\": \"enhancing tumour\"}\n",
    "    if train:\n",
    "        key = \"training\"\n",
    "        data_pairs = [{\"image\": img, \"label\": lbl} for (img, lbl) in zip(images, labels)]\n",
    "    else:\n",
    "        key = \"test\"\n",
    "        data_pairs = [{\"image\": img} for img in images]\n",
    "\n",
    "    dataset = {\n",
    "        \"labels\": labels_dict,\n",
    "        \"modality\": modality,\n",
    "        key: data_pairs,\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(data, \"dataset.json\"), \"w\") as outfile:\n",
    "        json.dump(dataset, outfile)\n",
    "\n",
    "\n",
    "def run_parallel(func, args):\n",
    "    return Parallel(n_jobs=os.cpu_count())(delayed(func)(arg) for arg in args)\n",
    "\n",
    "\n",
    "def prepare_dataset(data, train):\n",
    "    print(f\"Preparing BraTS23 dataset from: {data}\")\n",
    "    start = time.time()\n",
    "    run_parallel(prepare_nifty, sorted(glob(os.path.join(data, \"BraTS*\"))))\n",
    "    prepare_dirs(data, train)\n",
    "    prepare_dataset_json(data, train)\n",
    "    end = time.time()\n",
    "    print(f\"Preparing time: {(end - start):.2f}\")\n",
    "\n",
    "# prepare_dataset(\"/raid/compass/mobarak/datasets/brats2023/train/train_valid\", train=True)\n",
    "prepare_dataset(\"/raid/compass/mobarak/datasets/brats2023/valid/official_valid\", train=False)\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd6241f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing /raid/compass/mobarak/datasets/brats2023/valid/official_valid\n",
      "Pre-processing time: 212.71\n"
     ]
    }
   ],
   "source": [
    "!python3 preprocess.py --task 12 --ohe --exec_mode test --data /raid/compass/mobarak/datasets/brats2023/valid --results /raid/compass/mobarak/datasets/brats2023/valid/official_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c19bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export MKL_SERVICE_FORCE_INTEL=1\n",
    "!python main.py --brats --deep_supervision --depth 6 --filters 64 96 128 192 256 384 512 --min_fmap 2 --scheduler --learning_rate 0.0003 --epochs 200 --fold 0 --amp --gpus 1 --task 11 --save_ckpt --data /raid/compass/mobarak/datasets/brats2023/train/train_valid/11_3d --results /raid/compass/mobarak/datasets/brats2023/train/train_valid --ckpt_store_dir ckpt_ours"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
